{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn import preprocessing\n","import numpy as np\n","from collections import defaultdict\n","import os\n","import pickle\n","import scipy.stats as st\n","\n","from itertools import combinations\n","from scipy.stats import chi2\n","\n","from code.DataGeneration_class import DataGenerationBernoulli\n","from code.DataGeneration_class import DataGenerationPoisson"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# DATA GENERATION"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bernoulli"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1669626835064,"user":{"displayName":"Alessandra Ragni","userId":"15543420367377310453"},"user_tz":-60},"id":"3qrs1BB5yiNo"},"outputs":[],"source":["# BERNOULLI GENERATION \n","\n","for w in range(0,100):\n","  \n","  DG = DataGenerationBernoulli(False, True, 1)\n","  DG.set_parameters()\n","  eta, y = DG.compute_eta_and_y()\n","\n","  x1 = DG.fix[0]\n","\n","  g = []\n","  j = 1\n","  for i in y:\n","    g.append(np.repeat(j, len(i)))\n","    j = j + 1\n","\n","  y = np.hstack(y).squeeze()\n","  x1 = np.hstack(x1).squeeze()\n","  g = np.hstack(g).squeeze()\n","\n","  data = {'y': y, 'x1': x1, 'g': g}\n","  df = pd.DataFrame(data)\n","  \n","  filename = 'Bernoulli_' + str(w) +'.csv'\n","\n","  df.to_csv('output/comparison_state_of_art/Bernoulli_DG_output/' + filename)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Poisson"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8996,"status":"ok","timestamp":1669626983721,"user":{"displayName":"Alessandra Ragni","userId":"15543420367377310453"},"user_tz":-60},"id":"YyIpXZDBAiFp"},"outputs":[],"source":["from google.colab import files\n","\n","# POISSON GENERATION\n","\n","for w in range(0,100):\n","  \n","  DG = DataGenerationPoisson(False, True, 1)\n","  DG.set_parameters()\n","  eta, y = DG.compute_eta_and_y()\n","\n","  x1 = DG.fix[0]\n","\n","  g = []\n","  j = 1\n","  for i in y:\n","    g.append(np.repeat(j, len(i)))\n","    j = j + 1\n","\n","  y = np.hstack(y).squeeze()\n","  x1 = np.hstack(x1).squeeze()\n","  g = np.hstack(g).squeeze()\n","\n","  data = {'y': y, 'x1': x1, 'g': g}\n","  df = pd.DataFrame(data)\n","  \n","  filename = 'Poisson_' + str(w) +'.csv'\n","\n","  df.to_csv('output/comparison_state_of_art/Poisson_DG_output/' + filename)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# SPGLMM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from code.algorithm_alpha import algorithm_alpha\n","\n","def compute_order(knots):\n","    if knots.ndim > 1:\n","        return np.flip(np.argsort(knots[:, 0]))\n","    else:\n","        return np.flip(np.argsort(knots))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bernoulli"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Bernoulli\n","\n","results3 = pd.DataFrame(columns=['Sensitivity', 'Specificity', 'Accuracy'])\n","melt = pd.DataFrame(columns=['variable', 'value'])\n","\n","for file in os.listdir('/Bernoulli_datasets'):\n","  if file.endswith(\".csv\"):\n","    cond = True\n","    while cond:\n","        try:\n","            df = pd.read_csv('output/comparison_state_of_art/Bernoulli_DG_output/' + file).iloc[:,1:]\n","\n","            N = df.g.nunique()\n","            lengths = np.array(df.groupby('g').count().reset_index().iloc[:,1])\n","            y = list(df.groupby('g')['y'].apply(np.array).values)\n","\n","            fix = defaultdict(list)\n","\n","            fix[0] = df.groupby('g')['x1'].apply(np.array).values.tolist()\n","\n","            ran_var = False\n","            ran_int = True\n","            n_fix = 1\n","            tol = 0.05\n","            sim = True\n","\n","            #ran_var, ran_int, n_fix, sim, tol, model, fix, lengths, y, N\n","            knots, par, W, hess_ran, hess_fix = algorithm_alpha(ran_var, ran_int, n_fix, sim, tol, model = 'B', \n","                                                                fix=None, lengths=None, y=None, N=None)\n","\n","            x = compute_order(knots)\n","            knots = knots[x]\n","            W = W[:, x]\n","\n","            group = np.array([np.nan if np.sum(W[i,:])==0 else np.argmax(W[i,:]) for i in range(N)])\n","\n","            if len(knots)==3:\n","              cond = False\n","        except:\n","            pass\n","    \n","    df['ran_int'] = df['g'].apply(lambda x: knots[0] if x == 1 or x == 2 else knots[2] if x == 8 or x == 9 or x == 10 else knots[1])\n","    df['beta1'] = np.repeat(par, len(df))\n","\n","    temp = df['beta1'] * df['x1'] + df['ran_int']\n","    df['y_pred'] = temp.apply(lambda x: 1 if np.exp(x)/(1+np.exp(x)) > 0.5 else 0)\n","\n","\n","    # Append rows in Empty Dataframe by adding dictionaries\n","    melt = melt.append({'variable': 'c1,1', 'value': knots[0]}, ignore_index=True)\n","    melt = melt.append({'variable': 'c1,2', 'value': knots[1]}, ignore_index=True)\n","    melt = melt.append({'variable': 'c1,3', 'value': knots[2]}, ignore_index=True)\n","    melt = melt.append({'variable': 'beta1', 'value': par[0]}, ignore_index=True)\n","    print(melt)\n","\n","    confusion_matrix = pd.crosstab(df['y'], df['y_pred'], rownames=['Actual'], colnames=['Predicted'])\n","\n","    TN = confusion_matrix[0][0]\n","    TP = confusion_matrix[1][1]\n","    FN = confusion_matrix[0][1]\n","    FP = confusion_matrix[1][0]\n","\n","    Sensitivity = TP/(TP + FN) \n","    Specificity = TN/(TN + FP) \n","    Accuracy = (TN + TP)/(TN+TP+FN+FP) \n","\n","    # Append rows in Empty Dataframe by adding dictionaries\n","    results3 = results3.append({'Sensitivity': Sensitivity, 'Specificity': Specificity, 'Accuracy': Accuracy}, ignore_index=True)\n","    print(results3)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1669626835065,"user":{"displayName":"Alessandra Ragni","userId":"15543420367377310453"},"user_tz":-60},"id":"KQBY_GFtBFbk"},"outputs":[],"source":["filename = 'results3' + '.csv'\n","results3.to_csv('output/comparison_state_of_art/Bernoulli_SPGLMM_output/' + filename)\n","\n","filename = 'melt' +'.csv'\n","melt.to_csv('output/comparison_state_of_art/Bernoulli_SPGLMM_output/' + filename)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Poisson"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# POISSON\n","results3_POI = pd.DataFrame(columns=['MSE', 'MSE_log', 'Chi-Squared-Error'])\n","melt_POI = pd.DataFrame(columns=['variable', 'value'])\n","\n","for file in os.listdir('output/comparison_state_of_art/Poisson_DG_output/'):\n","  if file.endswith(\".csv\"):\n","    cond = True\n","    while cond:\n","        try:\n","            df = pd.read_csv('output/comparison_state_of_art/Poisson_DG_output/' + file).iloc[:,1:]\n","\n","            N = df.g.nunique()\n","            lengths = np.array(df.groupby('g').count().reset_index().iloc[:,1])\n","            y = list(df.groupby('g')['y'].apply(np.array).values)\n","\n","            fix = defaultdict(list)\n","\n","            fix[0] = df.groupby('g')['x1'].apply(np.array).values.tolist()\n","\n","            ran_var = False\n","            ran_int = True\n","            n_fix = 1\n","            tol = 0.05\n","            sim = True\n","\n","            knots, par, W, hess_ran, hess_fix = algorithm_alpha(ran_var, ran_int, n_fix, sim, tol, model = 'P', \n","                                                                fix=None, lengths=None, y=None, N=None)\n","\n","            x = compute_order(knots)\n","            knots = knots[x]\n","            W = W[:, x]\n","\n","            group = np.array([np.nan if np.sum(W[i,:])==0 else np.argmax(W[i,:]) for i in range(N)])\n","\n","            if len(knots)==3:\n","              cond = False\n","        except:\n","            pass\n","    \n","    df['ran_int'] = df['g'].apply(lambda x: knots[0] if x == 1 or x == 2 else knots[2] if x == 8 or x == 9 or x == 10 else knots[1])\n","    df['beta1'] = np.repeat(par, len(df))\n","\n","    temp = df['beta1'] * df['x1'] + df['ran_int']\n","    df['y_pred'] = temp.apply(lambda x: round(np.exp(x)))\n","\n","    # Append rows in Empty Dataframe by adding dictionaries\n","    melt_POI = melt_POI.append({'variable': 'c1,1', 'value': knots[0]}, ignore_index=True)\n","    melt_POI = melt_POI.append({'variable': 'c1,2', 'value': knots[1]}, ignore_index=True)\n","    melt_POI = melt_POI.append({'variable': 'c1,3', 'value': knots[2]}, ignore_index=True)\n","    melt_POI = melt_POI.append({'variable': 'beta1', 'value': par[0]}, ignore_index=True)\n","    print(melt_POI)\n","\n","    MSE = np.mean((df['y'] - df['y_pred'])**2)\n","    MSE_log = np.mean((np.log(df['y']+1) - np.log(df['y_pred']+1))**2)\n","    CSE = np.mean((df['y'] - df['y_pred'])**2 / (df['y_pred']+1))\n","\n","\n","    # Append rows in Empty Dataframe by adding dictionaries\n","    results3_POI = results3_POI.append({'MSE': MSE, 'MSE_log': MSE_log, 'Chi-Squared-Error': CSE}, ignore_index=True)\n","    print(results3_POI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filename = 'results3_POI' + '.csv'\n","results3_POI.to_csv('output/comparison_state_of_art/Poisson_SPGLMM_output/' + filename)\n","\n","filename = 'melt_POI' +'.csv'\n","melt_POI.to_csv('output/comparison_state_of_art/Poisson_SPGLMM_output/' + filename)\n","\n","#from google.colab import files\n","\n","#files.download('melt_POI' + '.csv')\n","#files.download('results3_POI' +'.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM2apmXJdOEkhPEAjo5Zvmy","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
